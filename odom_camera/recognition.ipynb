{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def preprocess(image_path):\n",
    "    img = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        img = img[y:y+h, x:x+w]     # Crop the face\n",
    "    img = img / 255.0               # Normalize\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare training data\n",
    "# Assuming you have some face images stored in a directory \"faces\"\n",
    "# Each subdirectory in \"faces\" represents a person\n",
    "faces_dir = r'G:\\datasets\\faces\\FaceData\\FaceDataset'\n",
    "faces_dirs = os.listdir(faces_dir)\n",
    "faces, labels = [], []\n",
    "MinImagesPerLabel = 40\n",
    "\n",
    "for label in range(800):\n",
    "    subject_dir_path = faces_dir + \"/\" + str(label)\n",
    "    subject_images_names = os.listdir(subject_dir_path)\n",
    "    labelfaces = []\n",
    "    \n",
    "    for image_name in subject_images_names:\n",
    "        image_path = subject_dir_path + \"/\" + image_name\n",
    "        image = preprocess(image_path)\n",
    "        if image.shape[0] and image.shape[1]:\n",
    "            # do NOT use np.resize.. use either skimage or cv resize\n",
    "            image = resize(image, (100, 100))\n",
    "            labelfaces.append(image)\n",
    "\n",
    "    if len(labelfaces) > MinImagesPerLabel:\n",
    "        labels.extend([label] * len(labelfaces))\n",
    "        faces.extend(labelfaces)\n",
    "\n",
    "np.save('TrainingFacesArr', np.array(faces))\n",
    "np.save('TrainingLabelsArr', np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = np.load('TrainingFacesArr.npy')\n",
    "labels = np.load('TrainingLabelsArr.npy')\n",
    "# Step 2: Train the EigenFace Recognizer keeping only 50 PCA components\n",
    "face_recognizer = cv.face.EigenFaceRecognizer_create(num_components=50)\n",
    "face_recognizer.train(faces, labels)\n",
    "face_recognizer.write('FaceRecogModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognizer = cv.face.EigenFaceRecognizer_create()\n",
    "face_recognizer.read('FaceRecogModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = face_recognizer.getEigenVectors()               # comps(10000x50)\n",
    "mean = face_recognizer.getMean()                \n",
    "first_comp = np.reshape(mean + comps[:,0], (100, 100))  # reshape to 100x100\n",
    "io.imshow(first_comp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the same analysis usig sk-learn PCA class\n",
    "# faces = np.load('./TrainingFacesArr.npy')\n",
    "# labels = np.load('./TrainingLabelsArr.npy')\n",
    "X, y = np.array(faces).reshape((-1,10000)), np.array(labels)\n",
    "from sklearn.decomposition import PCA\n",
    "comp = PCA(50)\n",
    "pca_first_comp = comp.mean_.reshape(100, 100) \\\n",
    "    + comp.components_[0].reshape(100, 100)\n",
    "io.imshow(pca_first_comp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 3.532263644629077\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_img = preprocess(r'G:\\datasets\\faces\\ExtractedFaces\\ExtractedFaces\\117\\29.jpg')\n",
    "test_img = resize(test_img, (100, 100))\n",
    "label, confidence = face_recognizer.predict(test_img)\n",
    "print(label, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt = comp.fit_transform(X)\n",
    "test_img = test_img.reshape(-1, 10000)\n",
    "transform_im = comp.transform(test_img)\n",
    "n_labels = np.unique(y)\n",
    "# mean_labels = np.zeros((len(n_labels), transform_im.shape[1]))\n",
    "# for id, label in enumerate(n_labels):\n",
    "#     mean_labels[id] = Xt[labels==label].mean(axis=0)\n",
    "# norm = np.linalg.norm(transform_im - mean_labels, axis=1)\n",
    "# prediction = np.argmin(norm)\n",
    "# n_labels[prediction], norm[prediction]\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(Xt, y)\n",
    "y_pred = clf.predict(transform_im)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
